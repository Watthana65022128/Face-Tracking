'use client'
import { useState, useEffect, useRef, useCallback } from 'react'
import { MediaPipeDetector, FaceTrackingData } from '@/lib/mediapipe-detector'
import { Button } from '@/app/components/ui/Button'
import { Card } from '@/app/components/ui/Card'

interface FaceTrackerProps {
  onTrackingStop: () => void
  sessionName?: string
}

export function FaceTracker({ onTrackingStop, sessionName = '‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ö' }: FaceTrackerProps) {
  const [isActive, setIsActive] = useState(false)
  const [currentData, setCurrentData] = useState<FaceTrackingData | null>(null)
  const [stats, setStats] = useState({
    totalDetections: 0,
    faceAwayCount: 0,
    duration: 0
  })

  const videoRef = useRef<HTMLVideoElement>(null)
  const canvasRef = useRef<HTMLCanvasElement>(null)
  const detectorRef = useRef<MediaPipeDetector | null>(null)
  const streamRef = useRef<MediaStream | null>(null)
  const intervalRef = useRef<NodeJS.Timeout | null>(null)
  const startTimeRef = useRef<number>(0)

  // ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞ MediaPipe
  const initializeCamera = useCallback(async () => {
    try {
      console.log('üé• ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á...')
      
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          width: { ideal: 1280 },
          height: { ideal: 720 },
          facingMode: 'user'
        },
        audio: false
      })

      if (videoRef.current) {
        videoRef.current.srcObject = stream
        streamRef.current = stream
        
        videoRef.current.onloadedmetadata = () => {
          videoRef.current?.play()
          console.log('‚úÖ ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô')
        }
      }

      // ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô MediaPipe detector
      if (!detectorRef.current) {
        detectorRef.current = new MediaPipeDetector()
        const initialized = await detectorRef.current.initialize()
        
        if (!initialized) {
          throw new Error('MediaPipe initialization failed')
        }
      }

      return true
    } catch (error) {
      console.error('‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á:', error)
      alert('‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï')
      return false
    }
  }, [])

  // ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á
  const stopCamera = useCallback(() => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop())
      streamRef.current = null
    }

    if (videoRef.current) {
      videoRef.current.srcObject = null
    }

    if (detectorRef.current) {
      detectorRef.current.destroy()
      detectorRef.current = null
    }

    console.log('üé• ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏õ‡∏¥‡∏î‡πÅ‡∏•‡πâ‡∏ß')
  }, [])

  // ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÅ‡∏ö‡∏ö real-time
  const performDetection = useCallback(async () => {
    if (!detectorRef.current || !videoRef.current || !isActive) return

    try {
      const timestamp = performance.now()
      const trackingData = await detectorRef.current.detectFromVideo(videoRef.current, timestamp)
      
      if (trackingData) {
        setCurrentData(trackingData)
        
        // ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ face orientation)
        setStats(prev => {
          const newStats = {
            ...prev,
            totalDetections: prev.totalDetections + 1,
            duration: Math.floor((timestamp - startTimeRef.current) / 1000)
          }

          // ‡∏ô‡∏±‡∏ö‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Å‡∏≤‡∏£‡∏´‡∏±‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏à‡∏≠
          if (trackingData.orientation.isLookingAway) {
            newStats.faceAwayCount++
          }

          return newStats
        })

        // ‡∏ß‡∏≤‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ö‡∏ô canvas
        drawDetectionOverlay(trackingData)
      }
    } catch (error) {
      console.error('‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö:', error)
    }
  }, [isActive])

  // ‡∏ß‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ö‡∏ô canvas
  const drawDetectionOverlay = useCallback((data: FaceTrackingData) => {
    const canvas = canvasRef.current
    const video = videoRef.current
    
    if (!canvas || !video) return

    const ctx = canvas.getContext('2d')
    if (!ctx) return

    // ‡∏•‡πâ‡∏≤‡∏á canvas
    ctx.clearRect(0, 0, canvas.width, canvas.height)

    if (!data.isDetected) {
      // ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
      ctx.fillStyle = 'rgba(255, 0, 0, 0.8)'
      ctx.font = '24px Arial'
      ctx.fillText('‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤', 50, 50)
      return
    }

    // ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏µ‡∏ï‡∏≤‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ face orientation)
    let borderColor = '#10B981' // ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß (‡∏õ‡∏Å‡∏ï‡∏¥)
    
    if (data.orientation.isLookingAway) {
      borderColor = '#EF4444' // ‡πÅ‡∏î‡∏á (‡∏´‡∏±‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏à‡∏≠)
    }

    // ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
    ctx.strokeStyle = borderColor
    ctx.lineWidth = 4
    const frameSize = Math.min(canvas.width, canvas.height) * 0.6
    const x = (canvas.width - frameSize) / 2
    const y = (canvas.height - frameSize) / 2
    
    ctx.strokeRect(x, y, frameSize, frameSize)

    // ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ face orientation)
    ctx.fillStyle = borderColor
    ctx.font = '16px Arial'
    
    const statusTexts = [
      `Face: ${data.isDetected ? '‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö' : '‡πÑ‡∏°‡πà‡∏û‡∏ö'}`,
      `Orientation: ${data.orientation.isLookingAway ? '‡∏´‡∏±‡∏ô‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏à‡∏≠' : '‡∏°‡∏≠‡∏á‡∏ï‡∏£‡∏á'}`,
      `Yaw: ${data.orientation.yaw.toFixed(1)}¬∞`,
      `Pitch: ${data.orientation.pitch.toFixed(1)}¬∞`
    ]

    statusTexts.forEach((text, index) => {
      ctx.fillText(text, 20, canvas.height - 100 + (index * 25))
    })
  }, [])

  // ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°
  const startTracking = useCallback(async () => {
    const initialized = await initializeCamera()
    if (!initialized) return

    setIsActive(true)
    startTimeRef.current = performance.now()
    
    // ‡πÄ‡∏£‡∏¥‡πà‡∏° detection loop
    intervalRef.current = setInterval(performDetection, 100) // ‡∏ó‡∏∏‡∏Å 100ms
    
    console.log('üéØ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°')
  }, [initializeCamera, performDetection])

  // ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°
  const stopTracking = useCallback(() => {
    setIsActive(false)
    
    if (intervalRef.current) {
      clearInterval(intervalRef.current)
      intervalRef.current = null
    }
    
    stopCamera()
    onTrackingStop()
    
    console.log('‚èπÔ∏è ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°', stats)
  }, [stopCamera, onTrackingStop, stats])

  // Cleanup ‡πÄ‡∏°‡∏∑‡πà‡∏≠ component unmount
  useEffect(() => {
    return () => {
      if (intervalRef.current) {
        clearInterval(intervalRef.current)
      }
      stopCamera()
    }
  }, [stopCamera])

  // ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡∏ô‡∏≤‡∏î canvas ‡πÄ‡∏°‡∏∑‡πà‡∏≠ video ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à
  useEffect(() => {
    const video = videoRef.current
    const canvas = canvasRef.current
    
    if (video && canvas) {
      const updateCanvasSize = () => {
        canvas.width = video.videoWidth
        canvas.height = video.videoHeight
      }
      
      video.addEventListener('loadedmetadata', updateCanvasSize)
      return () => video.removeEventListener('loadedmetadata', updateCanvasSize)
    }
  }, [])

  const formatTime = (seconds: number) => {
    const minutes = Math.floor(seconds / 60)
    const secs = seconds % 60
    return `${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
  }

  // Auto-start tracking when component mounts
  useEffect(() => {
    if (!isActive) {
      startTracking()
    }
  }, [isActive, startTracking]) // Run once on mount

  return (
    <Card className="w-full h-full">
      <div className="p-6">
        

        {/* Video and Canvas Container */}
        <div className="relative mb-6">
          <video
            ref={videoRef}
            className="w-full h-auto rounded-lg bg-black"
            autoPlay
            muted
            playsInline
          />
          <canvas
            ref={canvasRef}
            className="absolute inset-0 w-full h-full"
            style={{ pointerEvents: 'none' }}
          />
          
          
        </div>

        {/* Live Stats - ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Face Orientation */}
        {isActive && (
          <div className="grid grid-cols-2 md:grid-cols-3 gap-4 mb-6">
            <div className="bg-blue-50 p-4 rounded-lg text-center">
              <div className="text-2xl font-bold text-blue-600">{stats.totalDetections}</div>
              <div className="text-sm text-blue-500">‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö</div>
            </div>
            
            <div className="bg-red-50 p-4 rounded-lg text-center">
              <div className="text-2xl font-bold text-red-600">{stats.faceAwayCount}</div>
              <div className="text-sm text-red-500">‡∏´‡∏±‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏à‡∏≠</div>
            </div>
            
            <div className="bg-green-50 p-4 rounded-lg text-center">
              <div className="text-2xl font-bold text-green-600">
                {stats.totalDetections > 0 ? Math.round(((stats.totalDetections - stats.faceAwayCount) / stats.totalDetections) * 100) : 0}%
              </div>
              <div className="text-sm text-green-500">‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡∏°‡∏≠‡∏á‡∏ï‡∏£‡∏á</div>
            </div>
          </div>
        )}

        {/* Current Detection Status - ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Face Orientation */}
        {isActive && currentData && (
          <div className="bg-gray-50 p-4 rounded-lg">
            <h3 className="font-semibold mb-2">‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô:</h3>
            <div className="grid grid-cols-2 md:grid-cols-4 gap-2 text-sm">
              <div className={`p-2 rounded ${currentData.isDetected ? 'bg-green-100 text-green-800' : 'bg-red-100 text-red-800'}`}>
                Face: {currentData.isDetected ? '‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö' : '‡πÑ‡∏°‡πà‡∏û‡∏ö'}
              </div>
              <div className={`p-2 rounded ${currentData.orientation.isLookingAway ? 'bg-red-100 text-red-800' : 'bg-green-100 text-green-800'}`}>
                Head: {currentData.orientation.isLookingAway ? '‡∏´‡∏±‡∏ô‡∏≠‡∏≠‡∏Å' : '‡∏°‡∏≠‡∏á‡∏ï‡∏£‡∏á'}
              </div>
              <div className="p-2 rounded bg-blue-100 text-blue-800">
                Yaw: {currentData.orientation.yaw.toFixed(1)}¬∞
              </div>
              <div className="p-2 rounded bg-blue-100 text-blue-800">
                Pitch: {currentData.orientation.pitch.toFixed(1)}¬∞
              </div>
            </div>
          </div>
        )}

        {/* Control Buttons */}
        {isActive && (
          <div className="flex justify-center mt-6">
            <Button
              onClick={stopTracking}
              variant="secondary"
              className="px-8 py-3"
            >
              ‚èπÔ∏è ‡∏´‡∏¢‡∏∏‡∏î‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°
            </Button>
          </div>
        )}
      </div>
    </Card>
  )
}