// MediaPipe face detection and tracking utilities
import { FaceLandmarker, FilesetResolver, NormalizedLandmark } from '@mediapipe/tasks-vision';

export interface FaceTrackingData {
  isDetected: boolean;
  orientation: {
    yaw: number;
    pitch: number;
    isLookingAway: boolean;
  };
  confidence: number;
  timestamp: number;
  landmarks?: NormalizedLandmark[];
}

export class MediaPipeDetector {
  private faceLandmarker: FaceLandmarker | null = null;
  private isInitialized: boolean = false;
  private lastDetection: FaceTrackingData | null = null;

  async initialize(): Promise<boolean> {
    try {
      console.log('üéØ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÇ‡∏´‡∏•‡∏î MediaPipe FaceLandmarker...');
      
      // ‡∏•‡∏≠‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏´‡∏≤‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏£‡∏Å‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
      const filesetResolver = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
      );
      console.log('‚úÖ FilesetResolver ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à');

      // ‡∏•‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î model ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢‡∏Å‡πà‡∏≠‡∏ô (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ GPU)
      this.faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
          delegate: "CPU"
        },
        outputFaceBlendshapes: false, // ‡∏õ‡∏¥‡∏î‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏†‡∏≤‡∏£‡∏∞
        outputFacialTransformationMatrixes: false, // ‡∏õ‡∏¥‡∏î‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏†‡∏≤‡∏£‡∏∞
        runningMode: "VIDEO",
        numFaces: 1
      });

      this.isInitialized = true;
      console.log('‚úÖ MediaPipe FaceLandmarker ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô');
      return true;
    } catch (error) {
      console.error('‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î MediaPipe:', error);
      console.error('‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î:', error instanceof Error ? error.message : String(error));
      
      // ‡∏•‡∏≠‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
      return await this.initializeFallback();
    }
  }

  private async initializeFallback(): Promise<boolean> {
    try {
      console.log('üîÑ ‡∏•‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î MediaPipe ‡πÅ‡∏ö‡∏ö‡∏™‡∏≥‡∏£‡∏≠‡∏á...');
      
      // ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ CDN ‡∏ï‡πà‡∏≤‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ
      const filesetResolver = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.22/wasm"
      );

      this.faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
        baseOptions: {
          delegate: "CPU"
        },
        runningMode: "VIDEO",
        numFaces: 1
      });

      this.isInitialized = true;
      console.log('‚úÖ MediaPipe FaceLandmarker ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏ö‡∏ö‡∏™‡∏≥‡∏£‡∏≠‡∏á');
      return true;
    } catch (fallbackError) {
      console.error('‚ùå ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏ö‡∏ö‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏Å‡πá‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à:', fallbackError);
      return false;
    }
  }

  async detectFromVideo(video: HTMLVideoElement, timestamp: number): Promise<FaceTrackingData | null> {
    if (!this.isInitialized || !this.faceLandmarker) {
      console.warn('‚ö†Ô∏è MediaPipe ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô');
      return null;
    }

    try {
      // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö video readiness
      if (!video || video.readyState < 2) {
        console.warn('‚ö†Ô∏è Video ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏° readyState:', video?.readyState);
        return null;
      }

      console.log('üîç ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å detectForVideo...', { timestamp, videoWidth: video.videoWidth, videoHeight: video.videoHeight });
      const results = this.faceLandmarker.detectForVideo(video, timestamp);
      console.log('üìä MediaPipe results:', { 
        hasLandmarks: !!results.faceLandmarks, 
        landmarkCount: results.faceLandmarks?.length || 0,
        firstFaceLandmarks: results.faceLandmarks?.[0]?.length || 0
      });
      
      if (!results.faceLandmarks || results.faceLandmarks.length === 0) {
        console.log('‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô MediaPipe results');
        const noFaceData: FaceTrackingData = {
          isDetected: false,
          orientation: { yaw: 0, pitch: 0, isLookingAway: false },
          confidence: 0,
          timestamp
        };
        
        this.lastDetection = noFaceData;
        return noFaceData;
      }

      const landmarks = results.faceLandmarks[0];
      console.log('‚úÖ ‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤! landmarks:', landmarks.length, '‡∏à‡∏∏‡∏î');
      const trackingData = this.analyzeLandmarks(landmarks, timestamp);
      console.log('üìà tracking data:', trackingData);
      
      this.lastDetection = trackingData;
      return trackingData;
    } catch (error) {
      console.error('‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤:', error);
      return null;
    }
  }


  getLastDetection(): FaceTrackingData | null {
    return this.lastDetection;
  }

  private analyzeLandmarks(landmarks: NormalizedLandmark[], timestamp: number): FaceTrackingData {
    // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Å‡∏≤‡∏£‡∏´‡∏±‡∏ô‡∏´‡∏ô‡πâ‡∏≤ (Face Orientation)
    const orientation = this.calculateFaceOrientation(landmarks);
    
    return {
      isDetected: true,
      orientation,
      confidence: 0.95, // MediaPipe ‡∏°‡∏±‡∏Å‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤ confidence ‡∏™‡∏π‡∏á
      timestamp,
      landmarks // ‡∏™‡πà‡∏á landmarks ‡∏ó‡∏±‡πâ‡∏á 468 ‡∏à‡∏∏‡∏î‡πÑ‡∏õ‡πÉ‡∏´‡πâ component
    };
  }

  private calculateFaceOrientation(landmarks: NormalizedLandmark[]) {
    // ‡πÉ‡∏ä‡πâ‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ï‡∏≤‡∏° MediaPipe FaceMesh 468 landmarks
    const noseTip = landmarks[1];        // ‡∏à‡∏°‡∏π‡∏Å‡∏õ‡∏•‡∏≤‡∏¢
    const leftEyeInner = landmarks[133]; // ‡∏°‡∏∏‡∏°‡πÉ‡∏ô‡∏ï‡∏≤‡∏ã‡πâ‡∏≤‡∏¢
    const rightEyeInner = landmarks[362]; // ‡∏°‡∏∏‡∏°‡πÉ‡∏ô‡∏ï‡∏≤‡∏Ç‡∏ß‡∏≤
    const leftEyeOuter = landmarks[33];   // ‡∏°‡∏∏‡∏°‡∏ô‡∏≠‡∏Å‡∏ï‡∏≤‡∏ã‡πâ‡∏≤‡∏¢  
    const rightEyeOuter = landmarks[263]; // ‡∏°‡∏∏‡∏°‡∏ô‡∏≠‡∏Å‡∏ï‡∏≤‡∏Ç‡∏ß‡∏≤
    const chin = landmarks[18];           // ‡∏Ñ‡∏≤‡∏á
    const forehead = landmarks[10];       // ‡∏´‡∏ô‡πâ‡∏≤‡∏ú‡∏≤‡∏Å

    // Debug: ‡πÅ‡∏™‡∏î‡∏á coordinates ‡∏Ç‡∏≠‡∏á‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
    console.log('üéØ Landmark Coordinates:', {
      noseTip: { x: noseTip.x, y: noseTip.y },
      leftEyeInner: { x: leftEyeInner.x, y: leftEyeInner.y },
      rightEyeInner: { x: rightEyeInner.x, y: rightEyeInner.y },
      leftEyeOuter: { x: leftEyeOuter.x, y: leftEyeOuter.y },
      rightEyeOuter: { x: rightEyeOuter.x, y: rightEyeOuter.y },
      chin: { x: chin.x, y: chin.y },
      forehead: { x: forehead.x, y: forehead.y }
    });

    // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì yaw (‡∏´‡∏±‡∏ô‡∏ã‡πâ‡∏≤‡∏¢-‡∏Ç‡∏ß‡∏≤) ‡∏î‡πâ‡∏ß‡∏¢‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ï‡∏≤ - **‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á**
    const leftEyeWidth = Math.abs(leftEyeOuter.x - leftEyeInner.x);
    const rightEyeWidth = Math.abs(rightEyeOuter.x - rightEyeInner.x);
    
    // **‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á**: ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏´‡∏±‡∏ô‡∏ã‡πâ‡∏≤‡∏¢ ratio < 1, ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏´‡∏±‡∏ô‡∏Ç‡∏ß‡∏≤ ratio > 1
    // MediaPipe ‡∏û‡∏¥‡∏Å‡∏±‡∏î: ‡∏ï‡∏≤‡∏ã‡πâ‡∏≤‡∏¢ = ‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á (‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡∏ß‡∏≤‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠), ‡∏ï‡∏≤‡∏Ç‡∏ß‡∏≤ = ‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠
    const eyeRatio = leftEyeWidth / rightEyeWidth; // ‡∏Ñ‡∏∑‡∏ô‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏î‡∏¥‡∏°
    let yaw = (1 - eyeRatio) * 100; // ‡∏™‡∏•‡∏±‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢: (1 - ratio) ‡πÅ‡∏ó‡∏ô (ratio - 1)
    yaw = Math.max(-60, Math.min(60, yaw)); // ‡∏à‡∏≥‡∏Å‡∏±‡∏î range
    
    // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì pitch (‡∏´‡∏±‡∏ô‡∏ö‡∏ô-‡∏•‡πà‡∏≤‡∏á) ‡∏î‡πâ‡∏ß‡∏¢‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏à‡∏°‡∏π‡∏Å-‡∏Ñ‡∏≤‡∏á
    const noseToForeheadDistance = Math.abs(noseTip.y - forehead.y);
    const noseToChinDistance = Math.abs(chin.y - noseTip.y);
    
    const verticalRatio = noseToForeheadDistance / noseToChinDistance;
    let pitch = (verticalRatio - 0.6) * 200; // ‡∏õ‡∏£‡∏±‡∏ö scale
    pitch = Math.max(-45, Math.min(45, pitch)); // ‡∏à‡∏≥‡∏Å‡∏±‡∏î range

    // **‡∏õ‡∏£‡∏±‡∏ö threshold ‡πÉ‡∏´‡∏°‡πà** - ‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô 8-10¬∞ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á
    const YAW_THRESHOLD = 10;      // ‡∏≠‡∏á‡∏®‡∏≤ (‡∏•‡∏î‡∏à‡∏≤‡∏Å 15 ‡πÄ‡∏õ‡πá‡∏ô 10)
    const PITCH_THRESHOLD = 8;     // ‡∏≠‡∏á‡∏®‡∏≤ (‡∏•‡∏î‡∏à‡∏≤‡∏Å 15 ‡πÄ‡∏õ‡πá‡∏ô 8)
    
    // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏´‡∏±‡∏ô‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏à‡∏≠
    const isLookingAway = Math.abs(yaw) > YAW_THRESHOLD || Math.abs(pitch) > PITCH_THRESHOLD;

    // Debug logging ‡∏ó‡∏µ‡πà‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏¢‡∏¥‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô
    console.log(`üéØ Face Orientation Debug:`);
    console.log(`   Eye Widths - Left: ${leftEyeWidth.toFixed(4)}, Right: ${rightEyeWidth.toFixed(4)}`);
    console.log(`   Eye Ratio: ${eyeRatio.toFixed(4)}`);
    console.log(`   Nose-Forehead: ${noseToForeheadDistance.toFixed(4)}, Nose-Chin: ${noseToChinDistance.toFixed(4)}`);
    console.log(`   Vertical Ratio: ${verticalRatio.toFixed(4)}`);
    console.log(`   Final - Yaw: ${yaw.toFixed(1)}¬∞, Pitch: ${pitch.toFixed(1)}¬∞, Away: ${isLookingAway}`);

    return { yaw, pitch, isLookingAway };
  }

  destroy(): void {
    if (this.faceLandmarker) {
      this.faceLandmarker = null;
    }
    this.isInitialized = false;
    this.lastDetection = null;
    console.log('üßπ MediaPipe detector ‡∏ñ‡∏π‡∏Å‡∏•‡πâ‡∏≤‡∏á‡πÅ‡∏•‡πâ‡∏ß');
  }
}