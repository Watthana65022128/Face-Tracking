// MediaPipe face detection and tracking utilities
import { FaceLandmarker, FilesetResolver, NormalizedLandmark } from '@mediapipe/tasks-vision';

export interface FaceTrackingData {
  isDetected: boolean;
  orientation: {
    yaw: number;
    pitch: number;
    roll: number;
    isLookingAway: boolean;
  };
  mouth: {
    isOpen: boolean;
    openingRatio: number;
    isMoving: boolean;
  };
  eyes: {
    gazeDirection: 'CENTER' | 'LEFT' | 'RIGHT' | 'UP' | 'DOWN';
    isLookingAtScreen: boolean;
  };
  confidence: number;
  timestamp: number;
}

export class MediaPipeDetector {
  private faceLandmarker: FaceLandmarker | null = null;
  private isInitialized: boolean = false;
  private lastDetection: FaceTrackingData | null = null;
  private detectionHistory: FaceTrackingData[] = [];
  private readonly maxHistorySize = 10;

  async initialize(): Promise<boolean> {
    try {
      console.log('üéØ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÇ‡∏´‡∏•‡∏î MediaPipe FaceLandmarker...');
      
      const filesetResolver = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.22-rc.20250304/wasm"
      );

      this.faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
          delegate: "GPU"
        },
        outputFaceBlendshapes: true,
        outputFacialTransformationMatrixes: true,
        runningMode: "VIDEO",
        numFaces: 1
      });

      this.isInitialized = true;
      console.log('‚úÖ MediaPipe FaceLandmarker ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô');
      return true;
    } catch (error) {
      console.error('‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î MediaPipe:', error);
      return false;
    }
  }

  async detectFromVideo(video: HTMLVideoElement, timestamp: number): Promise<FaceTrackingData | null> {
    if (!this.isInitialized || !this.faceLandmarker) {
      console.warn('‚ö†Ô∏è MediaPipe ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô');
      return null;
    }

    try {
      const results = this.faceLandmarker.detectForVideo(video, timestamp);
      
      if (!results.faceLandmarks || results.faceLandmarks.length === 0) {
        const noFaceData: FaceTrackingData = {
          isDetected: false,
          orientation: { yaw: 0, pitch: 0, roll: 0, isLookingAway: false },
          mouth: { isOpen: false, openingRatio: 0, isMoving: false },
          eyes: { gazeDirection: 'CENTER', isLookingAtScreen: true },
          confidence: 0,
          timestamp
        };
        
        this.updateHistory(noFaceData);
        return noFaceData;
      }

      const landmarks = results.faceLandmarks[0];
      const trackingData = this.analyzeLandmarks(landmarks, timestamp);
      
      this.updateHistory(trackingData);
      this.lastDetection = trackingData;
      
      return trackingData;
    } catch (error) {
      console.error('‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤:', error);
      return null;
    }
  }

  private analyzeLandmarks(landmarks: NormalizedLandmark[], timestamp: number): FaceTrackingData {
    // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Å‡∏≤‡∏£‡∏´‡∏±‡∏ô‡∏´‡∏ô‡πâ‡∏≤ (Face Orientation)
    const orientation = this.calculateFaceOrientation(landmarks);
    
    // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏Ç‡∏≠‡∏á‡∏õ‡∏≤‡∏Å (Mouth Movement)
    const mouth = this.calculateMouthMovement(landmarks);
    
    // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏≠‡∏á (Eye Gaze)
    const eyes = this.calculateEyeGaze(landmarks);
    
    return {
      isDetected: true,
      orientation,
      mouth,
      eyes,
      confidence: 0.95, // MediaPipe ‡∏°‡∏±‡∏Å‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤ confidence ‡∏™‡∏π‡∏á
      timestamp
    };
  }

  private calculateFaceOrientation(landmarks: NormalizedLandmark[]) {
    // ‡πÉ‡∏ä‡πâ‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Å‡∏≤‡∏£‡∏´‡∏±‡∏ô‡∏´‡∏ô‡πâ‡∏≤
    const noseTip = landmarks[1];           // ‡∏à‡∏°‡∏π‡∏Å
    const chin = landmarks[18];             // ‡∏Ñ‡∏≤‡∏á
    const leftCheek = landmarks[116];       // ‡πÅ‡∏Å‡πâ‡∏°‡∏ã‡πâ‡∏≤‡∏¢
    const rightCheek = landmarks[345];      // ‡πÅ‡∏Å‡πâ‡∏°‡∏Ç‡∏ß‡∏≤
    const forehead = landmarks[10];         // ‡∏´‡∏ô‡πâ‡∏≤‡∏ú‡∏≤‡∏Å

    // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì yaw (‡∏Å‡∏≤‡∏£‡∏´‡∏±‡∏ô‡∏ã‡πâ‡∏≤‡∏¢-‡∏Ç‡∏ß‡∏≤)
    const yaw = Math.atan2(rightCheek.x - leftCheek.x, rightCheek.z - leftCheek.z) * 180 / Math.PI;
    
    // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì pitch (‡∏Å‡∏≤‡∏£‡∏´‡∏±‡∏ô‡∏ö‡∏ô-‡∏•‡πà‡∏≤‡∏á)  
    const pitch = Math.atan2(forehead.y - chin.y, forehead.z - chin.z) * 180 / Math.PI;
    
    // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì roll (‡∏Å‡∏≤‡∏£‡πÄ‡∏≠‡∏µ‡∏¢‡∏á‡∏ã‡πâ‡∏≤‡∏¢-‡∏Ç‡∏ß‡∏≤)
    const roll = Math.atan2(leftCheek.y - rightCheek.y, leftCheek.x - rightCheek.x) * 180 / Math.PI;

    // ‡∏Å‡∏≥‡∏´‡∏ô‡∏î threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ "‡∏´‡∏±‡∏ô‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏à‡∏≠"
    const YAW_THRESHOLD = 30;      // ‡∏≠‡∏á‡∏®‡∏≤
    const PITCH_THRESHOLD = 25;    // ‡∏≠‡∏á‡∏®‡∏≤
    
    const isLookingAway = Math.abs(yaw) > YAW_THRESHOLD || Math.abs(pitch) > PITCH_THRESHOLD;

    return { yaw, pitch, roll, isLookingAway };
  }

  private calculateMouthMovement(landmarks: NormalizedLandmark[]) {
    // ‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏õ‡∏≤‡∏Å
    const upperLip = landmarks[13];         // ‡∏£‡∏¥‡∏°‡∏ù‡∏µ‡∏õ‡∏≤‡∏Å‡∏ö‡∏ô
    const lowerLip = landmarks[14];         // ‡∏£‡∏¥‡∏°‡∏ù‡∏µ‡∏õ‡∏≤‡∏Å‡∏•‡πà‡∏≤‡∏á
    const leftCorner = landmarks[61];       // ‡∏°‡∏∏‡∏°‡∏õ‡∏≤‡∏Å‡∏ã‡πâ‡∏≤‡∏¢
    const rightCorner = landmarks[291];     // ‡∏°‡∏∏‡∏°‡∏õ‡∏≤‡∏Å‡∏Ç‡∏ß‡∏≤

    // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏õ‡∏≤‡∏Å (mouth opening)
    const mouthHeight = Math.abs(upperLip.y - lowerLip.y);
    const mouthWidth = Math.abs(leftCorner.x - rightCorner.x);
    
    // ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î‡∏õ‡∏≤‡∏Å
    const openingRatio = mouthHeight / mouthWidth;
    
    // threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î‡∏õ‡∏≤‡∏Å
    const MOUTH_OPEN_THRESHOLD = 0.04;
    const isOpen = openingRatio > MOUTH_OPEN_THRESHOLD;
    
    // ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏Ç‡∏≠‡∏á‡∏õ‡∏≤‡∏Å (‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥)
    let isMoving = false;
    if (this.detectionHistory.length > 3) {
      const recentRatios = this.detectionHistory.slice(-3).map(d => d.mouth.openingRatio);
      const ratioVariance = this.calculateVariance(recentRatios);
      isMoving = ratioVariance > 0.001; // threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß
    }

    return { isOpen, openingRatio, isMoving };
  }

  private calculateEyeGaze(landmarks: NormalizedLandmark[]) {
    // ‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏ï‡∏≤
    const leftEyeCenter = landmarks[33];    // ‡∏ï‡∏≤‡∏ã‡πâ‡∏≤‡∏¢
    const rightEyeCenter = landmarks[362];  // ‡∏ï‡∏≤‡∏Ç‡∏ß‡∏≤
    const noseTip = landmarks[1];           // ‡∏à‡∏°‡∏π‡∏Å (reference point)

    // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏∏‡∏î‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏î‡∏ß‡∏á‡∏ï‡∏≤
    const eyeCenterX = (leftEyeCenter.x + rightEyeCenter.x) / 2;
    const eyeCenterY = (leftEyeCenter.y + rightEyeCenter.y) / 2;

    // ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏à‡∏°‡∏π‡∏Å
    const gazeOffsetX = eyeCenterX - noseTip.x;
    const gazeOffsetY = eyeCenterY - noseTip.y;

    // ‡∏Å‡∏≥‡∏´‡∏ô‡∏î threshold ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏≠‡∏á
    const GAZE_THRESHOLD_X = 0.02;
    const GAZE_THRESHOLD_Y = 0.015;

    let gazeDirection: 'CENTER' | 'LEFT' | 'RIGHT' | 'UP' | 'DOWN' = 'CENTER';
    
    if (Math.abs(gazeOffsetX) > GAZE_THRESHOLD_X) {
      gazeDirection = gazeOffsetX > 0 ? 'RIGHT' : 'LEFT';
    } else if (Math.abs(gazeOffsetY) > GAZE_THRESHOLD_Y) {
      gazeDirection = gazeOffsetY > 0 ? 'DOWN' : 'UP';
    }

    // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏°‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    const isLookingAtScreen = gazeDirection === 'CENTER';

    return { gazeDirection, isLookingAtScreen };
  }

  private calculateVariance(values: number[]): number {
    if (values.length === 0) return 0;
    
    const mean = values.reduce((sum, val) => sum + val, 0) / values.length;
    const squaredDiffs = values.map(val => Math.pow(val - mean, 2));
    
    return squaredDiffs.reduce((sum, diff) => sum + diff, 0) / values.length;
  }

  private updateHistory(data: FaceTrackingData): void {
    this.detectionHistory.push(data);
    
    // ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏ô‡∏≤‡∏î history
    if (this.detectionHistory.length > this.maxHistorySize) {
      this.detectionHistory.shift();
    }
  }

  getLastDetection(): FaceTrackingData | null {
    return this.lastDetection;
  }

  getDetectionHistory(): FaceTrackingData[] {
    return [...this.detectionHistory];
  }

  destroy(): void {
    if (this.faceLandmarker) {
      this.faceLandmarker.close();
      this.faceLandmarker = null;
    }
    this.isInitialized = false;
    this.lastDetection = null;
    this.detectionHistory = [];
    console.log('üßπ MediaPipe detector ‡∏ñ‡∏π‡∏Å‡∏•‡πâ‡∏≤‡∏á‡πÅ‡∏•‡πâ‡∏ß');
  }
}